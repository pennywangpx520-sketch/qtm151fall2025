{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> Lecture 14 - Creating/replacing variables.</span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "- Starting a new module on **manipulating data** in Pandas\n",
    "- Will discuss adding new columns/variables to a DataFrame (data set)\n",
    "- Will cover **cleaning** data and **recoding** variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> I. Import Libraries and Data </span>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "Key libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Read dataset of car racing circuits\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Formula_One <br>\n",
    "- [See Data Source](https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits = pd.read_csv(\"data_raw/circuits.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> II. Examine Data </span>\n",
    "\n",
    "<font size = \"4\">\n",
    "Can view DataFrame using the DataWrangler extension on VS code. But information about the data can be accessed using Pandas commands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['circuitId' 'circuitRef' 'name' 'location' 'country' 'lat' 'lng' 'alt'\n",
      " 'url']\n",
      "\n",
      "(77, 9)\n",
      "\n",
      "# of rows: 77\n",
      "# of columns: 9\n"
     ]
    }
   ],
   "source": [
    "# column/variable headings\n",
    "print(circuits.columns.values)\n",
    "print()\n",
    "# number of rows and columns of DataFrame\n",
    "print(circuits.shape)\n",
    "print()\n",
    "n_rows, n_cols = circuits.shape\n",
    "print(\"# of rows:\", n_rows)\n",
    "print(\"# of columns:\", n_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "We can also get the DataTypes for each column (dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circuitId       int64\n",
      "circuitRef     object\n",
      "name           object\n",
      "location       object\n",
      "country        object\n",
      "lat           float64\n",
      "lng           float64\n",
      "alt            object\n",
      "url            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(circuits.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "We've seen \"circuits.apply\", \"circuits.shape\", \"circuits.dtypes\", which are all **attributes** of the Pandas DataFrame we named \"circuits\"\n",
    "\n",
    "The DataFrame also has **methods** (functions), like \"circuits.apply\" and \"circuits.mean\".\n",
    "\n",
    "How do we remember all of these?\n",
    "\n",
    "VS code can remind you of all available attributes and methods for an object. In the code cell below, type \"circuits.\" (with the period) and then wait, without running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type the following (including the period), then wait, without running the cell\n",
    "# type this >> circuits.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Note:** We've already seen how to add new columns/variables to a DataFrame. But we haven't seen how to rename the existing columns/variables. Some of the most straightforward are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['circuitId' 'circuitRef' 'name' 'location' 'country' 'lat' 'lng' 'alt'\n",
      " 'url']\n",
      "\n",
      "['ID_No' 'circuitRef' 'name' 'location' 'country' 'lat' 'lng' 'alt'\n",
      " 'Uniform Resource Locator']\n"
     ]
    }
   ],
   "source": [
    "# Change the first and last column headings\n",
    "print(circuits.columns.values)\n",
    "print()\n",
    "\n",
    "# Change last heading to \"Uniform Resource Locator\"\n",
    "circuits.columns.values[-1] = \"Uniform Resource Locator\"\n",
    "\n",
    "# Change first heading to \"ID_No\"\n",
    "circuits.columns.values[0] = \"ID_No\"\n",
    "print(circuits.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID_No' 'circuitRef' 'name' 'location' 'country' 'lat' 'lng' 'alt' 'url']\n"
     ]
    }
   ],
   "source": [
    "# Change back to \"url\" \n",
    "\n",
    "# Create a new data-frame and assign it to \"circuits\". \n",
    "# So we're overwriting the dataframe.\n",
    "circuits = circuits.rename(columns={'Uniform Resource Locator': 'url'})\n",
    "\n",
    "print(circuits.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['circuitID' 'circuitRef' 'name' 'location' 'country' 'lat' 'lng' 'alt'\n",
      " 'url']\n"
     ]
    }
   ],
   "source": [
    "# Change back to \"circuitID\"\n",
    "\n",
    "# Instead of making a new dataframe and over-writing the old one, change it \"in-place\"\n",
    "circuits.rename(columns={'ID_No':'circuitID'}, inplace=True)\n",
    "\n",
    "print(circuits.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> III. Cleaning Data </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Data that should be numerical (e.g. altitude of a Formula One track) can have missing values or non-numerical replacements (like \"N/A\"). We want to manipulate the data to allow for numerical calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.442925064935054\n",
      "1.0766831168831175\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not convert string '1018710913071322815310326444011621858357852235783745\\N3837130266581460882227345432011261771456364841391263960948515333279139790214816788156762028470531581819129551851941616782-710825515\\N\\N' to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(circuits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(circuits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlng\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(circuits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6548\u001b[0m ):\n\u001b[0;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[1;32m  12421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m  12422\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[1;32m  12378\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  12379\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6452\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[1;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6456\u001b[0m     )\n\u001b[0;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    723\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_float(x) \u001b[38;5;129;01mor\u001b[39;00m is_integer(x) \u001b[38;5;129;01mor\u001b[39;00m is_complex(x)):\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1703\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(x)\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert string '1018710913071322815310326444011621858357852235783745\\N3837130266581460882227345432011261771456364841391263960948515333279139790214816788156762028470531581819129551851941616782-710825515\\N\\N' to numeric"
     ]
    }
   ],
   "source": [
    "print(circuits[\"lat\"].mean())\n",
    "print(circuits[\"lng\"].mean())\n",
    "print(circuits[\"alt\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circuitID       int64\n",
      "circuitRef     object\n",
      "name           object\n",
      "location       object\n",
      "country        object\n",
      "lat           float64\n",
      "lng           float64\n",
      "alt            object\n",
      "url            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Let's try to figure out the problem\n",
    "print(circuits.dtypes)\n",
    "\n",
    "# The column \"alt\" has the DataType \"object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      10\n",
      "1      18\n",
      "2       7\n",
      "3     109\n",
      "4     130\n",
      "     ... \n",
      "72    108\n",
      "73    255\n",
      "74     15\n",
      "75     \\N\n",
      "76     \\N\n",
      "Name: alt, Length: 77, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(circuits[\"alt\"])\n",
    "# these look like numbers, except the last two are \"\\N\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "- Each column of a Pandas DataFrame is a Pandas Series\n",
    "- Each Pandas Series with \"dtype: object\" has a collection of methods known as \"String Methods\"\n",
    "- To execute a method from this collection you must type: ``series_name.str.method_name``\n",
    "- **NOTE**: Whenever I type something with a vague placeholder name like \"series_name\" or \"method_name\" this means that you should replace that word/phrase with an actual Python object or method/function name\n",
    "- Within this collection, there is a method we want to use called ``.isnumeric``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "\n",
      "<class 'pandas.core.strings.accessor.StringMethods'>\n",
      "\n",
      "<class 'method'>\n"
     ]
    }
   ],
   "source": [
    "# This is a Pandas Series\n",
    "print(type(circuits[\"alt\"])) \n",
    "print()\n",
    "# This is a Pandas StringMethods object (collection of methods/functions)\n",
    "print(type(circuits[\"alt\"].str)) \n",
    "print()\n",
    "# This is a method/function belonging to the StringMethods collection\n",
    "print(type(circuits[\"alt\"].str.isnumeric)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "You'll get an error if you try to use ``.str`` with a column that doesn't have the \"object\" dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m circuits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6297\u001b[0m ):\n\u001b[1;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/strings/accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(data)\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/strings/accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "circuits[\"lat\"].str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "The ``series_name.str.isnumeric()`` method returns a Pandas Series with ``True`` everywhere the Series entry is deemed \"numeric\" and ``False`` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      True\n",
      "1      True\n",
      "2      True\n",
      "3      True\n",
      "4      True\n",
      "      ...  \n",
      "72     True\n",
      "73     True\n",
      "74     True\n",
      "75    False\n",
      "76    False\n",
      "Name: alt, Length: 77, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(circuits[\"alt\"].str.isnumeric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    circuitID circuitRef                            name   location  \\\n",
      "22         80      vegas  Las Vegas Strip Street Circuit  Las Vegas   \n",
      "71         73       baku               Baku City Circuit       Baku   \n",
      "75         78     losail    Losail International Circuit  Al Daayen   \n",
      "76         79      miami   Miami International Autodrome      Miami   \n",
      "\n",
      "          country      lat       lng alt  \\\n",
      "22  United States  36.1147 -115.1730  \\N   \n",
      "71     Azerbaijan  40.3725   49.8533  -7   \n",
      "75          Qatar  25.4900   51.4542  \\N   \n",
      "76            USA  25.9581  -80.2389  \\N   \n",
      "\n",
      "                                                  url  \n",
      "22  https://en.wikipedia.org/wiki/Las_Vegas_Grand_...  \n",
      "71     http://en.wikipedia.org/wiki/Baku_City_Circuit  \n",
      "75  http://en.wikipedia.org/wiki/Losail_Internatio...  \n",
      "76  http://en.wikipedia.org/wiki/Miami_Internation...  \n"
     ]
    }
   ],
   "source": [
    "# We can reference subattributes of columns in \".query()\"\n",
    "non_numeric = circuits.query(\"  alt.str.isnumeric() == False \")\n",
    "print(non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Why is the string \"-7\" considered non-numeric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\\\N' '-7']\n"
     ]
    }
   ],
   "source": [
    "# The pd.unique() function extracts unique values from a series/array\n",
    "\n",
    "unique_non_numeric = pd.unique( non_numeric[\"alt\"] )\n",
    "print(unique_non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "We'll decide what we should replace \"\\N\" and \"-7\" with\n",
    "\n",
    "- \"-7\" is easy. We'll replace the string \"-7\" with the integer -7\n",
    "- What about \"\\N\"? It turns out the best choice is the \"nan\" (not a number) object from the Numpy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(np.nan)\n",
    "\n",
    "# ironically, the type of this object is a floating-point number...\n",
    "print(type(np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_non_numeric is the list with [\"\\\\N\", \"-7\"]\n",
    "# we'll make a list of the same length with the values we want to replace them with\n",
    "\n",
    "replace_vals = [np.nan, -7]\n",
    "\n",
    "# Overwrite the \"alt\" column, replacing every appearance from unique_non_numeric with\n",
    "# the corresponding element of replace_vals\n",
    "circuits[\"alt\"] = circuits[\"alt\"].replace(unique_non_numeric, replace_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Did it work? Let's test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [circuitID, circuitRef, name, location, country, lat, lng, alt, url]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "non_numeric = circuits.query(\"  alt.str.isnumeric() == False  \")\n",
    "print(non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "There are no rows with a non-numeric value for \"alt\"! Are we done? (No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(circuits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6548\u001b[0m ):\n\u001b[0;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[1;32m  12421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m  12422\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[1;32m  12378\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  12379\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6452\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[1;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6456\u001b[0m     )\n\u001b[0;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/nanops.py:719\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    716\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[1;32m    720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/numpy/_core/_methods.py:53\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "print(circuits[\"alt\"].mean()) # get an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "What happened? We still don't have the right \"dtype\" to do calculations. We should have checked that in the first place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circuitID       int64\n",
      "circuitRef     object\n",
      "name           object\n",
      "location       object\n",
      "country        object\n",
      "lat           float64\n",
      "lng           float64\n",
      "alt            object\n",
      "url            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(circuits.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "The \"alt\" column still has the \"object\" dtype. But since we've cleaned the data, all of its elements **can be** converted to numeric values. The ``Pandas`` function ``to_numeric`` can be used to do this.\n",
    "\n",
    "We'll create a new column to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248.1891891891892\n"
     ]
    }
   ],
   "source": [
    "circuits[\"alt_numeric\"] = pd.to_numeric(circuits[\"alt\"])\n",
    "print(circuits[\"alt_numeric\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the cleaning process is done, you may want to store the dataset again\n",
    "# It's recommended to do this in a separate file from the original\n",
    "# That way you can always go back to the original if you made a programming error\n",
    "\n",
    "circuits.to_csv(\"data_clean/circuits.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise**: When I was creating this notebook, I had the following question. \"If I read in the .csv file I just created and save it as a new DataFrame, will I have to re-do any part of the cleaning process?\" Test this out for yourself.\n",
    "\n",
    "**Exercise**: Read in the .csv file that was just created, saving it as a new DataFrame. You'll see there is an extra column/variable called \"Unnamed\" with the values 0, 1, 2, ..., 75, 76. Type ``help(circuits.to_csv)`` to figure out how to create a new .csv file without this extra column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "248.1891891891892\n"
     ]
    }
   ],
   "source": [
    "# your answer here\n",
    "new_df = pd.read_csv(\"data_clean/circuits.csv\")\n",
    "\n",
    "# First, tried line below, got an error\n",
    "# non_num= new_df.query(\"  alt.str.isnumeric() == False  \")\n",
    "\n",
    "print(new_df[\"alt\"].dtype) \n",
    "# Since we cleaned this column, Pandas recognized all elements\n",
    "# were numerical and changed the dtype!!!\n",
    "\n",
    "print(new_df[\"alt\"].mean())\n",
    "\n",
    "# So no, don't need to do any re-cleaning. \n",
    "# Plus, \"alt_numeric\" turns out to be unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "circuits.to_csv(\"data_clean/circuits_no_idx.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise:**\n",
    "\n",
    "- Use \".replace()\" with the \"country\" column\n",
    "- Replace \"USA\" with \"United States\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your own code\n",
    "circuits[\"country\"] = circuits[\"country\"].replace(\"USA\", \"United States\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> IV. Recoding Variables</span>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "\"Recoding\" variables means changing/re-expressing existing variables into a new set of values that may be more useful for data analysis.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- A variable called \"age\" consists of integers beginning at 0 (how old the person is in terms of years). We can transform this into a categorical variable with the values \"child\", \"teenager\", \"young adult\", \"adult\", \"senior\"\n",
    "\n",
    "- A variable called \"submission_time\" records the time that a student submitted an assignment to Gradescope. We can transform this into a categorical variable with the values \"on time\" and \"late\"\n",
    "\n",
    "- A variable called \"candidate_preference\" is taken from a survey of people asking which of two presidential candidates they will vote for. This is a categorical variable with the values \"Candidate A\", \"Candidate B\", \"Don't Know\", \"Refused\", \"Blank\", \"Other Candidate\". This is recoded to another categorical variable with only 3 values \"Candidate A\", \"Candidate B\", and \"Neither\".\n",
    "\n",
    "- We convert a variable \"height\" measured in inches, to a corresponding variable measuring height in centimeters.\n",
    "\n",
    "- A variable called \"lat\" consists of floating point numbers consisting of a geographical coordinate measuring the distance north or south of the Equator. We change this into a categorical variable with the values \"north\" or \"south\".\n",
    "\n",
    "We'll perform this last one in 3 different ways. In each way, we will consider as \"south\" those circuits with $-90 < \\textrm{lat} \\leq 0$ and \"north\" as circuits with $0 < \\textrm{lat} \\leq 90$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = circuits.shape \n",
    "\n",
    "col_no = 5 # column 5 is \"lat\"\n",
    "hemisphere = []\n",
    "\n",
    "for k in range(nrows):\n",
    "    lat_val = circuits.iloc[k, col_no]\n",
    "    if lat_val <= 0:\n",
    "        hemisphere.append(\"South\")\n",
    "    else:\n",
    "        hemisphere.append(\"North\")\n",
    "\n",
    "# could overwrite \"lat\", but is almost always better to keep the original variable\n",
    "circuits[\"hemisphere\"] = hemisphere\n",
    "\n",
    "# Note: I made sure the data in this column didn't need to be cleaned first!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the column to verify the next cell actually works\n",
    "circuits[\"hemisphere\"] = \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hemisphere(lat):\n",
    "    if lat_val <= 0:\n",
    "        return \"South\" \n",
    "    else:\n",
    "        return \"North\"\n",
    "\n",
    "circuits[\"hemisphere\"] = circuits[\"lat\"].apply(check_hemisphere)\n",
    "\n",
    "# Q: What error did I make?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the column to verify the next cell actually works\n",
    "circuits[\"hemisphere\"] = \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Pandas function called \".cut\", which you can use to segment data\n",
    "# into intervals or \"bins\" \n",
    "\n",
    "lat_bins = [-90, 0, 90]\n",
    "# lat_bins = [float(\"-inf\"), 0, float(\"inf\")]\n",
    "\n",
    "lat_labels = [\"South\", \"North\"]\n",
    "circuits[\"hemisphere\"] = pd.cut(circuits[\"lat\"], \n",
    "                                bins = lat_bins,\n",
    "                                right = True,\n",
    "                                labels = lat_labels)\n",
    "\n",
    "\n",
    "# Note: if we set lat_bins = [float(\"-inf\"), 0, float(\"inf\")]\n",
    "# then intervals are \"Less than or equal to 0\" and \"Above 0\"\n",
    "# float(\"inf\") and float(\"-inf\") represent positive infinity and negative infinity\n",
    "# The \"right\" command indicates that the right interval is *inclusive*,\n",
    "# i.e. \"less than or equal to\"\n",
    "                            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise:** Recode the altitude variable into a categorial variable with the values\n",
    "\n",
    "- \"Low altitude\" if $\\textrm{altitude} \\leq 45$\n",
    "- \"Medium altitude\" if $45 < \\textrm{altitude} \\leq 145$\n",
    "- \"High altitude\" if $145 < \\textrm{altitude}$\n",
    "\n",
    "**Hint**: Should you use the original altitude column or the one we cleaned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "alt_bins = [float(\"-inf\"), 45, 145, float(\"inf\")]\n",
    "\n",
    "alt_labels = [\"Low altitude\", \"Medium altitude\", \"High altitude\"]\n",
    "circuits[\"alt_type\"] = pd.cut(circuits[\"alt_numeric\"], \n",
    "                                bins = alt_bins,\n",
    "                                right = True,\n",
    "                                labels = alt_labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise:** What happens if you use the ``Pandas`` function ``.cut`` if the bins you provide don't capture all the data in the column? What happens if there are missing values in the column? Test it out by recoding the altitude\n",
    "\n",
    "- \"Group A\" if $0 < \\textrm{altitude} \\leq 120$\n",
    "- \"Group B\" if $120 < \\textrm{altitude} \\leq 400$\n",
    "- \"Group C\" if $400 < \\textrm{altitude} \\leq 800$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29    NaN\n",
      "31    NaN\n",
      "35    NaN\n",
      "Name: alt_group, dtype: category\n",
      "Categories (3, object): ['Group A' < 'Group B' < 'Group C']\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "group_bins = [0, 120, 400, 800]\n",
    "\n",
    "group_labels = [\"Group A\", \"Group B\", \"Group C\"]\n",
    "circuits[\"alt_group\"] = pd.cut(circuits[\"alt_numeric\"], \n",
    "                                bins = group_bins,\n",
    "                                right = True,\n",
    "                                labels = group_labels)\n",
    "\n",
    "\n",
    "alt_over_800 = circuits.query(\"alt_numeric > 800\")\n",
    "print(alt_over_800[\"alt_group\"])\n",
    "# Looks like \"np.nan\" gets entered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
